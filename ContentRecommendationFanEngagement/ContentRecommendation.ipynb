{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KiranH1007/-MLB-fan-engagement-project/blob/handling-of-cloud-function-and-deployment-of-recommendation-function/Live%20Game%20Sentiment%20Analysis/ContentRecommendation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D7NXnwDgSmey"
      },
      "outputs": [],
      "source": [
        "# Install Required Libraries\n",
        "!pip install google-cloud-storage google-cloud-bigquery nltk pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3VAZpFJNTBkj"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "# Initialize GCS client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Specify your GCS bucket and file name\n",
        "bucket_name = 'gcp-mlb-hackathon-2025' # Make sure this is the correct bucket name\n",
        "blob_name = 'datasets/mlb-fan-content-interaction-data/2025-mlb-fan-favs-follows.json'\n",
        "\n",
        "# Get the blob directly without getting the bucket metadata first\n",
        "# This assumes the bucket is public and blob_name includes the full path\n",
        "blob = storage_client.bucket(bucket_name).blob(blob_name)\n",
        "\n",
        "# Download the file\n",
        "raw_data = blob.download_as_text()\n",
        "\n",
        "# Print the data (optional)\n",
        "#print(raw_data[0:100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Gg8bw6lf4WK"
      },
      "outputs": [],
      "source": [
        "# load json with pandas\n",
        "# Data set is 2025-mlb-fan-favs-follows.json\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.cloud import storage\n",
        "\n",
        "# Initialize GCS client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Specify your GCS bucket and file name\n",
        "bucket_name = 'gcp-mlb-hackathon-2025'\n",
        "blob_name = 'datasets/mlb-fan-content-interaction-data/2025-mlb-fan-favs-follows.json'\n",
        "\n",
        "# Get the blob directly\n",
        "blob = storage_client.bucket(bucket_name).blob(blob_name)\n",
        "\n",
        "# Download the file as bytes\n",
        "data = blob.download_as_bytes()\n",
        "\n",
        "# Decode the bytes to a string\n",
        "raw_data = data.decode('utf-8')\n",
        "\n",
        "# Load the data using json.loads to handle possible JSON Lines format\n",
        "try:\n",
        "    # Attempt to load as a single JSON object\n",
        "    json_data = json.loads(raw_data)\n",
        "    df_fanfav = pd.DataFrame([json_data]) # Enclose in a list if it's a single object\n",
        "except json.JSONDecodeError:\n",
        "    # If single object fails, try loading as JSON Lines\n",
        "    json_data = [json.loads(line) for line in raw_data.splitlines() if line.strip()]\n",
        "    df_fanfav = pd.DataFrame(json_data)\n",
        "\n",
        "# Preview data\n",
        "print(df_fanfav.head())\n",
        "\n",
        "print(df_fanfav.info())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z767Md64tgus"
      },
      "outputs": [],
      "source": [
        "# load json with pandas\n",
        "# data set altogether with  multiple json files\n",
        "# Note ******** currently doing with 5 files later do the Scalable\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.cloud import storage\n",
        "import re\n",
        "\n",
        "# Initialize GCS client\n",
        "storage_client = storage.Client()\n",
        "\n",
        "# Specify your GCS bucket and file name\n",
        "bucket_name = 'gcp-mlb-hackathon-2025'\n",
        "file_pattern = 'datasets/mlb-fan-content-interaction-data/'\n",
        "\n",
        "# List to store dataframes from each file\n",
        "all_dfs = []\n",
        "\n",
        "blobs = storage_client.list_blobs(bucket_name, prefix=file_pattern)\n",
        "# for blob in blobs:\n",
        "#     print(blob.name)\n",
        "\n",
        "filtered_blobs = [blob for blob in blobs if re.match(r'datasets/mlb-fan-content-interaction-data/mlb-fan-content-interaction-data-\\d+\\.json$', blob.name)]\n",
        "\n",
        "# limiting the dataset\n",
        "filtered_blobs = filtered_blobs[:5]\n",
        "\n",
        "for blob_name in filtered_blobs:\n",
        "\n",
        "       print(f\"Processing file: {blob_name.name}\")\n",
        "       # Get the blob directly\n",
        "       blob = storage_client.bucket(bucket_name).blob(blob_name.name)\n",
        "\n",
        "       # Download the file as bytes\n",
        "       data = blob.download_as_bytes()\n",
        "\n",
        "       # Decode the bytes to a string\n",
        "       raw_data = data.decode('utf-8')\n",
        "\n",
        "       # Load the data using json.loads\n",
        "       try:\n",
        "           json_data = json.loads(raw_data)\n",
        "           df = pd.DataFrame([json_data])\n",
        "       except json.JSONDecodeError:\n",
        "           json_data = [json.loads(line) for line in raw_data.splitlines() if line.strip()]\n",
        "           df = pd.DataFrame(json_data)\n",
        "\n",
        "       #print(df.head())\n",
        "       # Data Cleaning: Remove Redundancy (similar to your example)\n",
        "       df.drop(columns=['content_headline'], inplace=True, errors='ignore')  # Ignore if column doesn't exist\n",
        "       df['content_id'] = df['content_type'] + ':' + df['slug'].str.lower()\n",
        "       df.drop(columns=['slug', 'content_type'], inplace=True, errors='ignore')\n",
        "       df.drop(columns=['date_time_date'], inplace=True, errors='ignore')\n",
        "\n",
        "       # Add the cleaned dataframe to the list\n",
        "       all_dfs.append(df)\n",
        "\n",
        "final_df = pd.concat(all_dfs, ignore_index=True)\n",
        "\n",
        "final_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_uHfGTksBxcN"
      },
      "outputs": [],
      "source": [
        "# Analysis of DataFrames are named df_fanfav, final_df\n",
        "common_columns = list(set(df_fanfav.columns) & set(final_df.columns))\n",
        "print(\"Common Columns:\", common_columns)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7DX81VVC9HT"
      },
      "outputs": [],
      "source": [
        "#without cleanup and duplicate columns\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "# it should be outer for all unique data and inner for common data\n",
        "\n",
        "# Merge the result with the third dataset which has content type headline\n",
        "merged_df = pd.merge(df_fanfav, final_df, on=common_columns, how='outer')\n",
        "\n",
        "print(merged_df.count())\n",
        "\n",
        "merged_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XN-AnenyS_ca"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "with open('merged_df.pkl', 'wb') as f:\n",
        "   pickle.dump(merged_df, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p6VX8ZBjT46c"
      },
      "source": [
        "checkpoint saved for merged_df dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O47cNh4GT35p"
      },
      "outputs": [],
      "source": [
        "with open('merged_df.pkl', 'rb') as f:\n",
        "   merged_df = pickle.load(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5VDwVVjbWPHR"
      },
      "outputs": [],
      "source": [
        "user_row = merged_df[merged_df['user_id'] == 'some_user_id']\n",
        "print(user_row)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9GeJa0gYJfY"
      },
      "source": [
        "Fan Engagement Recommendation System using only in context with user id who followed  followed_player_ids column and player_tags based on content id column.\n",
        "1. Overview\n",
        "\n",
        "This system provides personalized content recommendations to fans based on their followed players and popular content. It leverages a dataset called merged_df, which contains information about users, their followed players, and content with associated player tags.\n",
        "\n",
        "2. Data Structure\n",
        "\n",
        "The system relies on the following data structures:\n",
        "\n",
        "user_player_mapping: A dictionary that maps each user ID to a set of player IDs they follow. This mapping is derived from the followed_player_ids column in merged_df.\n",
        "player_content_mapping: A dictionary that maps each player tag to a set of content IDs associated with that tag. This mapping is created using the player_tags and content_id columns in merged_df.\n",
        "3. Recommendation Logic\n",
        "\n",
        "The core recommendation logic is implemented in the recommend_content function:\n",
        "\n",
        "Input: The function takes a user_id and top_n (number of recommendations) as input.\n",
        "Player-Based Recommendations: If the user_id is found in user_player_mapping, it iterates through the followed players and retrieves associated content from player_content_mapping. These recommendations are added to a set called recommendations.\n",
        "Fallback: If no recommendations are found based on followed players (e.g., for new users), a fallback strategy is used. In this case, it recommends the most popular content from merged_df based on the content_id column.\n",
        "Output: The function returns a list of up to top_n recommended content IDs.\n",
        "4. Example Usage\n",
        "\n",
        "\n",
        "user_recommendations = recommend_content('some_user_id', top_n=5)\n",
        "for i in user_recommendations:\n",
        "    print(i)\n",
        "Use code with caution\n",
        "This code snippet demonstrates how to get recommendations for a specific user and print them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3g7ajWQVDlO"
      },
      "outputs": [],
      "source": [
        "# first sample takes more time\n",
        "# import pandas as pd\n",
        "# from collections import defaultdict\n",
        "\n",
        "# # 1. Build User-Player and Player-Content Mappings\n",
        "# user_player_mapping = defaultdict(set)\n",
        "# player_content_mapping = defaultdict(set)\n",
        "\n",
        "# for _, row in merged_df.iterrows():\n",
        "#     user_id = row['user_id']\n",
        "#     followed_players = row['followed_player_ids']\n",
        "#     content_id = row['content_id']\n",
        "#     player_tags = row['player_tags']\n",
        "\n",
        "#     if isinstance(followed_players, str):\n",
        "#         for player in followed_players.split(','):\n",
        "#             user_player_mapping[user_id].add(player.strip())\n",
        "\n",
        "#     if isinstance(player_tags, str):\n",
        "#         for tag in player_tags.split(','):\n",
        "#             player_content_mapping[tag.strip()].add(content_id)\n",
        "\n",
        "# print(user_player_mapping)\n",
        "# print(\"hi\")\n",
        "# print(player_content_mapping)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fVIP3MWrhnxV"
      },
      "outputs": [],
      "source": [
        "# Convert columns to string type, handling NaN values\n",
        "merged_df['followed_player_ids'] = merged_df['followed_player_ids'].astype(str)\n",
        "merged_df['player_tags'] = merged_df['player_tags'].astype(str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edMUr50OhLhC"
      },
      "outputs": [],
      "source": [
        "# optimised way\n",
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "\n",
        "# 1. Build User-Player Mapping\n",
        "# Explode followed_player_ids and apply a lambda function\n",
        "user_player_df = merged_df.assign(followed_player_ids=merged_df['followed_player_ids'].str.split(',')).explode('followed_player_ids')\n",
        "user_player_df['followed_player_ids'] = user_player_df['followed_player_ids'].str.strip()\n",
        "user_player_mapping1 = user_player_df.groupby('user_id')['followed_player_ids'].apply(set).to_dict()\n",
        "\n",
        "\n",
        "# 2. Build Player-Content Mapping\n",
        "# Explode player_tags and apply a lambda function\n",
        "player_content_df = merged_df.assign(player_tags=merged_df['player_tags'].str.split(',')).explode('player_tags')\n",
        "player_content_df['player_tags'] = player_content_df['player_tags'].str.strip()\n",
        "player_content_mapping1 = player_content_df.groupby('player_tags')['content_id'].apply(set).to_dict()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPaeQhtWinWp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Get a list of user IDs from the mapping\n",
        "user_ids = list(user_player_mapping1.keys())\n",
        "\n",
        "# Randomly select 5 user IDs\n",
        "sample_user_ids = random.sample(user_ids, 35)\n",
        "\n",
        "# Print the mappings for the selected user IDs M1RJCXEE8IY1NU5\n",
        "for user_id in sample_user_ids:\n",
        "  print(f\"User ID: {user_id}, Followed Players: {user_player_mapping1[user_id]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S3IAlR-fjSNt"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "# Get a list of user IDs from the mapping\n",
        "player_ids = list(player_content_mapping1.keys())\n",
        "\n",
        "for player_id in player_ids:\n",
        "  print(f\"player tags {player_id}, contentid: {player_content_mapping1[player_id]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMopkVJggaiS"
      },
      "outputs": [],
      "source": [
        "# 2. Recommendation Function\n",
        "def recommend_content(user_id, top_n=10):\n",
        "    recommendations = set()\n",
        "    if user_id in user_player_mapping1:\n",
        "        for player in user_player_mapping1[user_id]:\n",
        "            if player in player_content_mapping1:\n",
        "                recommendations.update(player_content_mapping1[player])\n",
        "                print(player_content_mapping1[player])\n",
        "\n",
        "    # Fallback (if no recommendations based on followed players)\n",
        "    if not recommendations:\n",
        "        print(\"no recommendation\")\n",
        "        # Recommend most popular content or other strategies\n",
        "        popular_content = merged_df['content_id'].value_counts().index.tolist()\n",
        "        recommendations.update(popular_content[:top_n])\n",
        "\n",
        "    return list(recommendations)[:top_n]\n",
        "\n",
        "# Example Usage:\n",
        "# user_recommendations = recommend_content('some_user_id', top_n=5)\n",
        "# for i in user_recommendations:\n",
        "#   print(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CH5CCLu_Xnt-"
      },
      "outputs": [],
      "source": [
        "# Use pickle to save these data structures to files. This makes them accessible to the Cloud Function later.\n",
        "import pickle\n",
        "\n",
        "with open('user_player_mapping1.pkl', 'wb') as f:\n",
        "    pickle.dump(user_player_mapping1, f)\n",
        "\n",
        "with open('player_content_mapping1.pkl', 'wb') as f:\n",
        "    pickle.dump(player_content_mapping1, f)\n",
        "\n",
        "popular_content = merged_df['content_id'].value_counts().index.tolist()\n",
        "with open('popular_content.pkl', 'wb') as f:\n",
        "    pickle.dump(popular_content, f)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvbbLQdVYqxn"
      },
      "source": [
        "### `Cloud Function`\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jbi-asdR8kJI"
      },
      "source": [
        "# Google cloud authentication and installation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Krs7lNOPNDLw"
      },
      "outputs": [],
      "source": [
        "!apt-get update && apt-get install -y google-cloud-sdk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O3kmgr-5NO4r"
      },
      "outputs": [],
      "source": [
        "!gcloud auth login"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynWaKf48Ncez"
      },
      "outputs": [],
      "source": [
        "# set the project id to fanengagementapp\n",
        "!gcloud config set project mlbfanengagementapp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlSGCgPh8pyQ"
      },
      "source": [
        "# Main.py which is function in google cloud deployment\n",
        "\n",
        "add requirements.txt and all pkl files and main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v6Q608s4ibj"
      },
      "outputs": [],
      "source": [
        "# location of pkl files\n",
        "# !ls -lh user_player_mapping1.pkl\n",
        "# !ls -lh player_content_mapping1.pkl\n",
        "# !ls -lh popular_content.pkl\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_9mYBB41Nuhj"
      },
      "outputs": [],
      "source": [
        "# Trial 1\n",
        "\n",
        "# import pickle\n",
        "\n",
        "# def recommend_content_cloud_function(request):\n",
        "#     \"\"\"HTTP Cloud Function to handle recommendation requests.\"\"\"\n",
        "\n",
        "#     # Load data from local files (will be packaged with the function)\n",
        "#     with open('user_player_mapping1.pkl', 'rb') as f:\n",
        "#         user_player_mapping1 = pickle.load(f)\n",
        "#     with open('player_content_mapping1.pkl', 'rb') as f:\n",
        "#         player_content_mapping1 = pickle.load(f)\n",
        "#     with open('popular_content.pkl', 'rb') as f:\n",
        "#         popular_content = pickle.load(f)\n",
        "\n",
        "#     # Get user_id from request\n",
        "#     request_json = request.get_json(silent=True)\n",
        "#     user_id = request_json.get('user_id', '')\n",
        "\n",
        "#     if not user_id:\n",
        "#         return {'error': 'Missing user_id in request'}, 400\n",
        "\n",
        "#     try:\n",
        "#         recommendations = set()\n",
        "#         if user_id in user_player_mapping1:\n",
        "#             for player in user_player_mapping1[user_id]:\n",
        "#                 if player in player_content_mapping1:\n",
        "#                     recommendations.update(player_content_mapping1[player])\n",
        "\n",
        "#         # Fallback\n",
        "#         if not recommendations:\n",
        "#             recommendations.update(popular_content)\n",
        "\n",
        "#         return {'recommendations': list(recommendations)[:10]}, 200\n",
        "\n",
        "#     except Exception as e:\n",
        "#         return {'error': str(e)}, 500"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7I6BJer5w7kw",
        "outputId": "7971c0f7-a172-42f2-eaeb-1e82b6f6e384"
      },
      "outputs": [],
      "source": [
        "# The Crucial Fix: Proper Logging and Error Handling: for cloud function optimization\n",
        "%%writefile main.py\n",
        "import pickle\n",
        "import logging\n",
        "import os \n",
        "\n",
        "def recommend_content_cloud_function(request):\n",
        "    \"\"\"HTTP Cloud Function to handle recommendation requests.\"\"\"\n",
        "\n",
        "    try:\n",
        "        # Load data from local files (will be packaged with the function)\n",
        "\n",
        "        print(\"Loading data from all pkl files\")\n",
        "\n",
        "        files_to_check = ['user_player_mapping1.pkl', 'player_content_mapping1.pkl', 'popular_content.pkl']\n",
        "        all_files_present = all(os.path.isfile(file) for file in files_to_check)\n",
        "\n",
        "        print(\"all pkl files are present and ready\")\n",
        "\n",
        "        if all_files_present:\n",
        "            try:\n",
        "                with open('user_player_mapping1.pkl', 'rb') as f:\n",
        "                    user_player_mapping1 = pickle.load(f)\n",
        "                with open('player_content_mapping1.pkl', 'rb') as f:\n",
        "                    player_content_mapping1 = pickle.load(f)\n",
        "                with open('popular_content.pkl', 'rb') as f:\n",
        "                    popular_content = pickle.load(f)\n",
        "                \n",
        "                print(\"Files loaded successfully\")\n",
        "            except Exception as e:\n",
        "                print(f\"An error occurred while loading files: {e}\")\n",
        "        else:\n",
        "            print(\"One or more files are missing.\")\n",
        "\n",
        "        if request.method == 'GET':  # Handle GET request\n",
        "            user_id = request.args.get('userid')\n",
        "            print(f\"Received GET request for user_id: {user_id}\") # Log the user_id\n",
        "\n",
        "        elif request.method == 'POST':  # Handle POST request (if needed)\n",
        "            request_json = request.get_json(silent=True)\n",
        "            user_id = request_json.get('user_id', '')\n",
        "            print(f\"Received POST request for user_id: {user_id}\") # Log the user_id\n",
        "\n",
        "        else:\n",
        "            logging.warning(f\"Received unsupported method: {request.method}\") # Log the request method\n",
        "            return 'Method Not Allowed', 405  # Return 405 for other methods\n",
        "\n",
        "        if not user_id:\n",
        "            logging.error(\"Missing user_id in request\") # Log the missing user_id error\n",
        "            return {'error': 'Missing user_id in request'}, 400\n",
        "\n",
        "        recommendations = set()\n",
        "        if user_id in user_player_mapping1:\n",
        "            for player in user_player_mapping1[user_id]:\n",
        "                if player in player_content_mapping1:\n",
        "                    recommendations.update(player_content_mapping1[player])\n",
        "\n",
        "        # Fallback\n",
        "        if not recommendations:\n",
        "            recommendations.update(popular_content)\n",
        "\n",
        "        result = {'recommendations': list(recommendations)[:10]}\n",
        "        print(f\"Recommendations for user {user_id}: {result}\") # Log the recommendations\n",
        "        return result, 200\n",
        "\n",
        "    except Exception as e:\n",
        "        logging.exception(f\"An error occurred: {e}\")  # Log the full exception with stack trace\n",
        "        return {'error': f\"Internal Server Error: {e}\"}, 500  # Return a 500 error\n",
        "\n",
        "# # Dummy request for testing\n",
        "# class DummyRequest:\n",
        "#     def __init__(self, args=None, json=None, method='GET'):\n",
        "#         self.args = args if args is not None else {}\n",
        "#         self._json = json if json is not None else {}\n",
        "#         self.method = method\n",
        "\n",
        "#     def get_json(self, silent=False):\n",
        "#         return self._json\n",
        "\n",
        "\n",
        "# request_get = DummyRequest(args={'userid': '7P45I0SCJ3AAIUW'})\n",
        "# response_get = recommend_content_cloud_function(request_get)\n",
        "\n",
        "# if response_get[1] == 200:\n",
        "#     print(\"Success:\", response_get[0])\n",
        "# else:\n",
        "#     print(\"Error:\", response_get)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhA_lnkkaJA5"
      },
      "outputs": [],
      "source": [
        "# all colab pip packages are there in requirements currently not required for so many packages in cloud\n",
        "#pip freeze > requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For Profiling that is memory and speed of execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!pip install line_profiler  # Install the line profiler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLMM9mFH_3Dh",
        "outputId": "8cb336d9-0a8c-4f8a-baf2-cd65bfeefe2b"
      },
      "outputs": [],
      "source": [
        "# #Improvised code with profiling and also testing with dummy user\n",
        "# %%writefile main.py\n",
        "# import time\n",
        "# import pickle\n",
        "# import logging\n",
        "# import psutil\n",
        "\n",
        "# # Configure logging (do this at the beginning of your function)\n",
        "# logging.basicConfig(level=logging.ERROR)\n",
        "\n",
        "# def recommend_content_cloud_function(request):\n",
        "#     \"\"\"HTTP Cloud Function to handle recommendation requests.\"\"\"\n",
        "#     start_time = time.time()  # Start timing the entire function\n",
        "\n",
        "#     try:\n",
        "#         # Load data from local files (will be packaged with the function)\n",
        "#         load_start = time.time()\n",
        "#         with open('user_player_mapping1.pkl', 'rb') as f:\n",
        "#             user_player_mapping1 = pickle.load(f)\n",
        "#         with open('player_content_mapping1.pkl', 'rb') as f:\n",
        "#             player_content_mapping1 = pickle.load(f)\n",
        "#         with open('popular_content.pkl', 'rb') as f:\n",
        "#             popular_content = pickle.load(f)\n",
        "#         load_end = time.time()\n",
        "#         print(f\"File loading time: {load_end - load_start} seconds\")\n",
        "\n",
        "#         if request.method == 'GET':  # Handle GET request\n",
        "#             user_id = request.args.get('userid')\n",
        "#             print(f\"Received GET request for user_id: {user_id}\")  # Log the user_id\n",
        "\n",
        "#         elif request.method == 'POST':  # Handle POST request (if needed)\n",
        "#             request_json = request.get_json(silent=True)\n",
        "#             user_id = request_json.get('user_id', '')\n",
        "#             print(f\"Received POST request for user_id: {user_id}\")  # Log the user_id\n",
        "\n",
        "#         else:\n",
        "#             logging.warning(f\"Received unsupported method: {request.method}\")  # Log the request method\n",
        "#             return 'Method Not Allowed', 405  # Return 405 for other methods\n",
        "\n",
        "#         if not user_id:\n",
        "#             logging.error(\"Missing user_id in request\")  # Log the missing user_id error\n",
        "#             return {'error': 'Missing user_id in request'}, 400\n",
        "\n",
        "#         recommendations = set()\n",
        "#         recommendation_start = time.time()\n",
        "#         if user_id in user_player_mapping1:\n",
        "#             for player in user_player_mapping1[user_id]:\n",
        "#                 if player in player_content_mapping1:\n",
        "#                     recommendations.update(player_content_mapping1[player])\n",
        "\n",
        "#         # Fallback\n",
        "#         if not recommendations:\n",
        "#             recommendations.update(popular_content)\n",
        "#         recommendation_end = time.time()\n",
        "#         print(f\"Recommendation logic time: {recommendation_end - recommendation_start} seconds\")\n",
        "\n",
        "#         result = {'recommendations': list(recommendations)[:10]}\n",
        "#         print(f\"Recommendations for user {user_id}: {result}\")  # Log the recommendations\n",
        "#         end_time = time.time()  # End timing the entire function\n",
        "#         print(f\"Total function execution time: {end_time - start_time} seconds\")\n",
        "#         return result, 200\n",
        "\n",
        "#     except Exception as e:\n",
        "#         logging.exception(f\"An error occurred: {e}\")  # Log the full exception with stack trace\n",
        "#         return {'error': f\"Internal Server Error: {e}\"}, 500  # Return a 500 error\n",
        "\n",
        "\n",
        "# # Dummy request for testing\n",
        "# class DummyRequest:\n",
        "#     def __init__(self, args=None, json=None, method='GET'):\n",
        "#         self.args = args if args is not None else {}\n",
        "#         self._json = json if json is not None else {}\n",
        "#         self.method = method\n",
        "\n",
        "#     def get_json(self, silent=False):\n",
        "#         return self._json\n",
        "\n",
        "\n",
        "# request_get = DummyRequest(args={'userid': '7P45I0SCJ3AAIUW'})\n",
        "# response_get = recommend_content_cloud_function(request_get)\n",
        "\n",
        "# if response_get[1] == 200:\n",
        "#     print(\"Success:\", response_get[0])\n",
        "# else:\n",
        "#     print(\"Error:\", response_get)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J03-P1eU9MBG"
      },
      "source": [
        "# Deployment of function to google cloud\n",
        "\n",
        "gcloud functions deploy recommend_content_cloud_function \\\n",
        "    --runtime python39 \\\n",
        "    --trigger-http \\\n",
        "    --source your-cloud-function-directory \\\n",
        "    --entry-point recommend_content_cloud_function \\\n",
        "    --memory 512M  # Or your chosen memory\n",
        "    --timeout 60s  # Set timeout to 60 seconds\n",
        "    --allow-unauthenticated # set for public url usecase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hwZh_8p0N__a"
      },
      "outputs": [],
      "source": [
        "!gcloud functions deploy recommend_content_cloud_function --runtime python39 --trigger-http --source /content/ --entry-point recommend_content_cloud_function --memory 512M "
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
